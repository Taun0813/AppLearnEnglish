# # mmm.py
# import time
# import re
# from datetime import date, datetime
# from openai import OpenAI
# import speech_recognition as sr
# import pyttsx3
# from PyQt5.QtWidgets import QWidget, QVBoxLayout, QPushButton, QLabel, QTextEdit
#
# # OpenAI client config
# client = OpenAI(
#     base_url="http://172.20.128.1:3000/v1",
#     api_key="lm-studio",
# )
#
# BOT_PROMPT = """
# B·∫°n l√† m·ªôt ng∆∞·ªùi b·∫°n ƒë·ªìng h√†nh gi√∫p luy·ªán nghe v√† luy·ªán n√≥i ti·∫øng Anh.
# H√£y giao ti·∫øp ƒë∆°n gi·∫£n, d·ªÖ hi·ªÉu, v√† ph·∫£n h·ªìi b·∫±ng ng√¥n ng·ªØ m√† ng∆∞·ªùi d√πng ƒë√£ s·ª≠ d·ª•ng trong c√¢u h·ªèi.
# """
#
# def summarize_text(text, max_sentences=3):
#     sentences = re.split(r'(?<=[.!?]) +', text)
#     summary = ' '.join(sentences[:max_sentences])
#     return summary.strip()
#
# class VoiceAssistantApp(QWidget):
#     def __init__(self):
#         super().__init__()
#         self.setWindowTitle("Voice Assistant - Luy·ªán n√≥i ti·∫øng Anh")
#         self.setGeometry(100, 100, 500, 400)
#
#         self.layout = QVBoxLayout()
#         self.listen_button = QPushButton("üé§ B·∫Øt ƒë·∫ßu nghe")
#         self.listen_button.clicked.connect(self.handle_listen)
#
#         self.user_input_label = QLabel("B·∫°n n√≥i:")
#         self.user_input_text = QTextEdit()
#         self.user_input_text.setReadOnly(True)
#
#         self.bot_reply_label = QLabel("Ph·∫£n h·ªìi t·ª´ tr·ª£ l√Ω:")
#         self.bot_reply_text = QTextEdit()
#         self.bot_reply_text.setReadOnly(True)
#
#         self.layout.addWidget(self.listen_button)
#         self.layout.addWidget(self.user_input_label)
#         self.layout.addWidget(self.user_input_text)
#         self.layout.addWidget(self.bot_reply_label)
#         self.layout.addWidget(self.bot_reply_text)
#
#         self.setLayout(self.layout)
#
#         # Voice setup
#         self.robot_ear = sr.Recognizer()
#         self.robot_mouth = pyttsx3.init()
#         self.messages = [{"role": "system", "content": BOT_PROMPT}]
#
#     def type_print_to_textbox(self, text, textbox, delay=0.01):
#         textbox.clear()
#         for char in text:
#             textbox.insertPlainText(char)
#             time.sleep(delay)
#
#     def handle_listen(self):
#         with sr.Microphone() as mic:
#             self.robot_ear.adjust_for_ambient_noise(mic, duration=0.5)
#             try:
#                 audio = self.robot_ear.listen(mic, timeout=5, phrase_time_limit=7)
#                 user_input = self.robot_ear.recognize_google(audio, language='vi-VN')
#                 self.user_input_text.setPlainText(user_input)
#             except sr.UnknownValueError:
#                 self.user_input_text.setPlainText("Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c gi·ªçng n√≥i.")
#                 return
#             except sr.WaitTimeoutError:
#                 self.user_input_text.setPlainText("Kh√¥ng nghe th·∫•y g√¨.")
#                 return
#
#         # Ph·∫£n h·ªìi ƒë·∫∑c bi·ªát
#         if "tho√°t" in user_input.lower():
#             self.bot_reply_text.setPlainText("T·∫°m bi·ªát nh√©!")
#             self.robot_mouth.say("T·∫°m bi·ªát nh√©!")
#             self.robot_mouth.runAndWait()
#             return
#
#         self.messages.append({"role": "user", "content": user_input})
#         response = client.chat.completions.create(
#             model="meta-llama-3.1-8b-instruct",
#             stream=True,
#             messages=self.messages
#         )
#
#         full_reply = ""
#         for chunk in response:
#             content = chunk.choices[0].delta.content or ""
#             full_reply += content
#
#         self.messages.append({"role": "assistant", "content": full_reply})
#         self.type_print_to_textbox(full_reply, self.bot_reply_text)
#
#         summary = summarize_text(full_reply)
#         self.robot_mouth.say(summary)
#         self.robot_mouth.runAndWait()
